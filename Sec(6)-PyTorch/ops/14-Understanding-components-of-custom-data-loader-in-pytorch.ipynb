{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4Qgp8HzZrm0"
   },
   "source": [
    "# Understanding components of custom data loader in pytorch\n",
    "![](https://drive.google.com/uc?id=1e92FXOYdRlmQTbK0WozmBN0ZO9KYCPJx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtAiycwpazTM"
   },
   "source": [
    "## Recap - Creating Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jS8ZLT-KZoha"
   },
   "outputs": [],
   "source": [
    "## Dataset used\n",
    "# https://www.kaggle.com/datasets/mirichoi0218/insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4161,
     "status": "ok",
     "timestamp": 1739288198255,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "IdSy8uU8aH50",
    "outputId": "df98ffe5-5246-49ce-d5b8-5f765f6ea44e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.6.17)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.3.0)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle) (3.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2306,
     "status": "ok",
     "timestamp": 1739288215129,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "Z5XrtQ1aaJFT",
    "outputId": "e8655cab-1fe1-46fe-a28c-55e96242fcd8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aman0\\anaconda3\\envs\\TorchLearnEnv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\aman0\\.cache\\kagglehub\\datasets\\mirichoi0218\\insurance\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"mirichoi0218/insurance\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1739288220644,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "DUmUISBOaKXr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1739288229005,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "la5P0MwjaMNj",
    "outputId": "b19709d8-b8d4-480a-c892-31323e2c2afe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['insurance.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"C:/Users/aman0/.cache/kagglehub/datasets/mirichoi0218/insurance/versions/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1739288237675,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "lmZ7YA0FaNLM"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(path, 'insurance.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1739288238204,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "IH1HuvQNaO8D",
    "outputId": "94f2c0d9-8b84-4d5c-fc36-54a36722869d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1739289375036,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "CQxYGzrPaSvj"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1739289376178,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "wSM7Swi8qLk4",
    "outputId": "ff9d113d-4617-453c-af9d-422289841844"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1739289376791,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "sGfgL-yDaUAr"
   },
   "outputs": [],
   "source": [
    "# Split dataset before encoding\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1739289377170,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "YVPjaoDiaVKj"
   },
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in ['sex', 'smoker', 'region']:\n",
    "    le = LabelEncoder()\n",
    "    train_df[col] = le.fit_transform(train_df[col])\n",
    "    test_df[col] = le.transform(test_df[col])\n",
    "    label_encoders[col] = le  # Store encoders for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1739289377638,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "JzBP9KpaaWr0"
   },
   "outputs": [],
   "source": [
    "# Features and target\n",
    "X_train = train_df.drop(columns=['charges'])\n",
    "y_train = train_df['charges']\n",
    "X_test = test_df.drop(columns=['charges'])\n",
    "y_test = test_df['charges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1739289377798,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "Qf_5SbrDqaTA",
    "outputId": "f92bc2a0-69f4-4785-d7df-edc3dd2d76a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1070, 6)\n",
      "(1070,)\n",
      "(268, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1739289378146,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "9qLnlWdlaYG8"
   },
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1739289378860,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "zE8IbkLXaZ2E"
   },
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1739289379094,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "MSwI_ddnq3EY",
    "outputId": "aef864bc-16d7-4eeb-888a-ac3d46e9324c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1070, 6])\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1739289379298,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "WrotwEKvabQ8"
   },
   "outputs": [],
   "source": [
    "# Define Neural Network Model\n",
    "class SimpleNNRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleNNRegressionModel, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1739289379726,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "n32yAoH8adCE"
   },
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "model = SimpleNNRegressionModel(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1739289380129,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "DeZEQX5NafB0"
   },
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1739289380692,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "wUhJ6jLRq8Jn",
    "outputId": "5018104b-940e-4515-c782-6ec278df457e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nx_train_tensor = 1000000 --> 10gb OOM - out of memory\\n1000000 --> weight and bias\\n\\nwe are teaching human : A book of 1000 pages --> student : 10 : student, i am not able to understand.\\n1000\\n10 --> 100\\n100 feedback = 1000 pages --> 1 epoch\\n\\n1000 pages total\\n100 epoch\\n10 pages feedback\\n100 iteration * 100\\n\\n\\n\\n100 epoch\\n1 epoch --> 1070 rows\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "x_train_tensor = 1000000 --> 10gb OOM - out of memory\n",
    "1000000 --> weight and bias\n",
    "\n",
    "we are teaching human : A book of 1000 pages --> student : 10 : student, i am not able to understand.\n",
    "1000\n",
    "10 --> 100\n",
    "100 feedback = 1000 pages --> 1 epoch\n",
    "\n",
    "1000 pages total\n",
    "100 epoch\n",
    "10 pages feedback\n",
    "100 iteration * 100\n",
    "\n",
    "\n",
    "\n",
    "100 epoch\n",
    "1 epoch --> 1070 rows\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ✅ Common Practice:\n",
    "# Model Type\tTypical clip_value\n",
    "# Small RNN / LSTM / GRU models\t1.0 to 5.0\n",
    "# Large Transformers (BERT, GPT)\t0.5 to 1.0\n",
    "# CNNs / Feedforward networks (rarely needed)\tUsually no clipping, or 2.0~5.0 if unstable\n",
    "\n",
    "# To prevent exploding gradients\n",
    "# ✅ Step-by-step:\n",
    "# Calculate total gradient norm (L2 norm) across all parameters:\n",
    "\n",
    "# total_norm\n",
    "# =\n",
    "# ∑\n",
    "# (\n",
    "# gradients\n",
    "# 2\n",
    "# )\n",
    "# total_norm= \n",
    "# ∑(gradients \n",
    "# 2\n",
    "#  )\n",
    "# ​\n",
    " \n",
    "# Compare total_norm with clip_value:\n",
    "\n",
    "# If:\n",
    "\n",
    "# total_norm\n",
    "# ≤\n",
    "# clip_value\n",
    "# total_norm≤clip_value\n",
    "# ➡ Do nothing, keep gradients as they are.\n",
    "\n",
    "# Else:\n",
    "\n",
    "# scale factor\n",
    "# =\n",
    "# clip_value\n",
    "# total_norm\n",
    "# scale factor= \n",
    "# total_norm\n",
    "# clip_value\n",
    "# ​\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4131,
     "status": "ok",
     "timestamp": 1739289403845,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "A4df6BdVahEz",
    "outputId": "cb0855e6-52e4-4aba-9814-63f641d8d0ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 46238456.0000\n",
      "Epoch [200/1000], Loss: 31916640.0000\n",
      "Epoch [300/1000], Loss: 29426798.0000\n",
      "Epoch [400/1000], Loss: 27384960.0000\n",
      "Epoch [500/1000], Loss: 26143540.0000\n",
      "Epoch [600/1000], Loss: 25205638.0000\n",
      "Epoch [700/1000], Loss: 24448342.0000\n",
      "Epoch [800/1000], Loss: 23932408.0000\n",
      "Epoch [900/1000], Loss: 23538004.0000\n",
      "Epoch [1000/1000], Loss: 23207750.0000\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 1000\n",
    "clip_value = 25\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(X_train_tensor)\n",
    "    loss = criterion(predictions, y_train_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4zi4gfSAxqEK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZadbvMwbICU"
   },
   "source": [
    "## Understanding Components of a Custom DataLoader in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGGNzveostxg"
   },
   "source": [
    "1. Dataset (torch.utils.data.Dataset)\n",
    "2. DataLoader (torch.utils.data.DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader is like generators in python which wraps the object into iterable and yield the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Dz8CiutTjKWf"
   },
   "outputs": [],
   "source": [
    "# Creating our custom Dataset in pytorch\n",
    "# Following are mandatory methods required to override\n",
    "# init() - initialised the dataset, loads data, applied preprocessing\n",
    "# len() - return the total numbers of samples in the dataset\n",
    "# getitem() - Defines how to retrieve a single data sample when an index is provide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1739289368192,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "31FD5rssuR7I"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1739289660538,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "06mLP19tuZXv"
   },
   "outputs": [],
   "source": [
    "class InsuranceDataset(Dataset):\n",
    "  def __init__(self, X, y):\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "    # any preprocessing\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "     features = torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "     target = torch.tensor(self.y.values[idx], dtype=torch.float32)\n",
    "     return features, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560      9193.83850\n",
       "1285     8534.67180\n",
       "1142    27117.99378\n",
       "969      8596.82780\n",
       "486     12475.35130\n",
       "           ...     \n",
       "1095     4561.18850\n",
       "1130     8582.30230\n",
       "1294    11931.12525\n",
       "860     46113.51100\n",
       "1126    10214.63600\n",
       "Name: charges, Length: 1070, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, pandas.core.series.Series)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train),type(y_train)\n",
    "# So X_train.values is not required as it already , y_train.values is required because its y_train[0] will return pandas based indexing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(9193.8385), np.float64(16884.924))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.values[0],y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1739289755799,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "J01Bztw9vgvi"
   },
   "outputs": [],
   "source": [
    "dataset = InsuranceDataset(X_train, y_train)\n",
    "# We are not using dataset for test data because it is smaller and can be passed to the model once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1739290199667,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "cLYHhS6Cv2uD"
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argument\tMeaning\n",
    "# dataset\tYour dataset object (could be TensorDataset, CustomDataset, etc.)\n",
    "# batch_size=32\tLoads data in batches of size 32\n",
    "# shuffle=True\tRandomly shuffle data at the start of each epoch (good for training)\n",
    "# num_workers=4\tUses 4 parallel worker processes to speed up data loading (especially useful if your dataset is large or on disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1739290284945,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "9F_ozVU0wN6U",
    "outputId": "da0bd8eb-0ff3-4245-f403-35b442411fd6"
   },
   "outputs": [],
   "source": [
    "for batch_idx, (features, targets) in enumerate(dataloader):\n",
    "  print(f\"Batch {batch_idx+1} :\")\n",
    "  print(\"Features : \", features.shape)\n",
    "  print(\"Targets : \", targets.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1739290544976,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "3DWAEttaynXR",
    "outputId": "c7fad2e1-c397-472c-cbc7-b0344733d7b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.4375"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1070/32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktDZgSZNwZLg"
   },
   "source": [
    "✅ ✅ Why is batch size important for gradient calculation?\n",
    "Larger batch → gradients computed over more data → smoother update\n",
    "Smaller batch → faster per-step iteration but noisier gradient estimate\n",
    "\n",
    "Batch size\tPros\tCons\n",
    "Small (like 16, 32)\tLess memory, faster per-step\tNoisy gradients\n",
    "Medium (64-128)\tGood balance\tNeeds more memory\n",
    "Large (256-1024)\tSmooth gradients\tRequires large GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 107395,
     "status": "ok",
     "timestamp": 1739290544930,
     "user": {
      "displayName": "nimoy",
      "userId": "12145814232676261569"
     },
     "user_tz": -330
    },
    "id": "uMF9PbIKxrU6",
    "outputId": "ee8025a6-957c-409e-9678-a7eb1b24a145"
   },
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (batch_X, batch_y) in enumerate(dataloader):\n",
    "      print(f\"Current batch : {batch_idx}\")\n",
    "      optimizer.zero_grad()\n",
    "      predictions = model(batch_X)\n",
    "      loss = criterion(predictions, batch_y)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      print(f'Batch [{batch_idx+1}/{len(dataloader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3WtvxMiZyecC"
   },
   "outputs": [],
   "source": [
    "# # For large datasets -- we use the dataset and dataloader to avoid oom, and for faster processing\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "# from PIL import Image\n",
    "# import os\n",
    "\n",
    "# class MyImageDataset(Dataset):\n",
    "#     def __init__(self, image_dir, labels_dict, transform=None):\n",
    "#         \"\"\"\n",
    "#         image_dir: Path to folder containing image files\n",
    "#         labels_dict: Dictionary mapping image filename to label (e.g., {'img1.jpg': 0, 'img2.jpg': 1, ...})\n",
    "#         transform: Optional torchvision transforms (like resize, normalize, etc.)\n",
    "#         \"\"\"\n",
    "#         self.image_dir = image_dir\n",
    "#         self.image_filenames = os.listdir(image_dir)\n",
    "#         self.labels_dict = labels_dict\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_filenames)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         image_name = self.image_filenames[idx]\n",
    "#         image_path = os.path.join(self.image_dir, image_name)\n",
    "\n",
    "#         # Load image\n",
    "#         image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "#         # Apply transforms (resize, normalize, etc.)\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "\n",
    "#         # Get label\n",
    "#         label = self.labels_dict.get(image_name, -1)  # -1 if label missing\n",
    "\n",
    "#         return image, label\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMY0K2KSUzJmxptxjT9Gsxv",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TorchLearnEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
